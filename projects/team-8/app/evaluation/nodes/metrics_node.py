"""
í˜¼ë™ í–‰ë ¬(Confusion Matrix) ê³„ì‚° ë° ê²°ê³¼ ë¦¬í¬íŠ¸ ì €ì¥ ë…¸ë“œ.

128ê±´ ë“± ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ í† í° ì œí•œ/í¬ë˜ì‹œ ëŒ€ë¹„:
  - init_eval_csv()ë¡œ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹œ CSV í—¤ë” ìƒì„±
  - append_record_to_csv()ë¡œ í‰ê°€ 1ê±´ ì™„ë£Œ ì‹œë§ˆë‹¤ í•œ ì¤„ì”© ì¦‰ì‹œ ì €ì¥
  - ì¤‘ê°„ ì‹¤íŒ¨í•´ë„ ì´ë¯¸ í‰ê°€ëœ ê±´ê¹Œì§€ ë³µêµ¬ ê°€ëŠ¥
"""

from __future__ import annotations

import csv
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING

import pandas as pd
from rich import print as rprint
from rich.table import Table

from app.evaluation.state import EvaluationRecord

if TYPE_CHECKING:
    from app.evaluation.graph import PipelineStats

# ê²°ê³¼ CSV ì €ì¥ ë””ë ‰í† ë¦¬ (nodes/ ê¸°ì¤€ ìƒìœ„ â†’ evaluation/results)
RESULTS_DIR = Path(__file__).resolve().parent.parent / "results"

# CSV ì»¬ëŸ¼ ìˆœì„œ (records_to_dataframeê³¼ ë™ì¼)
CSV_COLUMNS = [
    "íŒŒì¼ì´ë¦„",
    "ê²¬ë¬˜ì¢…",
    "ë‚˜ì´",
    "ê¸°ì €ì§ˆí™˜",
    "ì¶”ì¶œì§ˆë³‘ëª…",
    "ì•½ê´€ì›ë¬¸",
    "Judgeì˜ˆì¸¡",
    "Judgeì´ìœ ",
    "Evaluatorì •ë‹µ",
    "Evaluatorì´ìœ ",
    "ë¼ë²¨",
]


def print_dataset_summary(stats: PipelineStats, total_records: int) -> None:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ì˜ ë°ì´í„°ì…‹ êµ¬ì¶• ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

    "128ê°œì˜ ë°˜ë ¤ë™ë¬¼ ì •ë³´ - top-kê°œ ì§ˆë³‘ ì¶”ì¶œ - top-kê°œ ì•½ê´€ ì¶”ì¶œë¡œ ì´ Nê°œ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì˜€ìŠµë‹ˆë‹¤."
    í˜•íƒœì˜ ë¡œê¹…ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    avg_diseases = (
        sum(stats.disease_counts) / len(stats.disease_counts)
        if stats.disease_counts
        else 0
    )
    avg_policies_per_disease = (
        sum(stats.policy_counts_per_disease) / len(stats.policy_counts_per_disease)
        if stats.policy_counts_per_disease
        else 0
    )

    rprint()
    rprint("[bold cyan]â•â•â• ë°ì´í„°ì…‹ êµ¬ì¶• ìš”ì•½ â•â•â•[/bold cyan]")
    rprint(
        f"  {stats.total_yaml_files}ê°œì˜ ë°˜ë ¤ë™ë¬¼ ì •ë³´ "
        f"- í‰ê·  {avg_diseases:.1f}ê°œ ì§ˆë³‘ ì¶”ì¶œ "
        f"- ì§ˆë³‘ë‹¹ í‰ê·  {avg_policies_per_disease:.1f}ê°œ ì•½ê´€ ê²€ìƒ‰ìœ¼ë¡œ "
        f"ì´ [bold]{total_records}ê°œ[/bold] ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì˜€ìŠµë‹ˆë‹¤."
    )


def compute_and_display_metrics(
    records: list[EvaluationRecord],
    stats: PipelineStats | None = None,
) -> dict[str, int]:
    """í‰ê°€ ê²°ê³¼ì—ì„œ í˜¼ë™ í–‰ë ¬ì„ ê³„ì‚°í•˜ê³  Rich í…Œì´ë¸”ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    counts: dict[str, int] = {"TP": 0, "TN": 0, "FP": 0, "FN": 0}
    for record in records:
        counts[record.label] = counts.get(record.label, 0) + 1

    total = len(records)

    # â”€â”€ ë°ì´í„°ì…‹ êµ¬ì¶• ìš”ì•½ ì¶œë ¥ â”€â”€
    if stats is not None:
        print_dataset_summary(stats, total)

    # â”€â”€ í˜¼ë™ í–‰ë ¬ í…Œì´ë¸” â”€â”€
    matrix_table = Table(
        title="ğŸ” í˜¼ë™ í–‰ë ¬ (Confusion Matrix)",
        show_header=True,
        header_style="bold magenta",
    )
    matrix_table.add_column("", style="bold", width=25)
    matrix_table.add_column("Evaluator: ë³´ì¥(P)", justify="center", width=20)
    matrix_table.add_column("Evaluator: ë©´ì±…(N)", justify="center", width=20)

    matrix_table.add_row(
        "Judge: ë³´ì¥(P)",
        f"[green]TP = {counts['TP']}[/green]",
        f"[bold red]FP = {counts['FP']}[/bold red]",
    )
    matrix_table.add_row(
        "Judge: ë©´ì±…(N)",
        f"[yellow]FN = {counts['FN']}[/yellow]",
        f"[blue]TN = {counts['TN']}[/blue]",
    )

    rprint()
    rprint(matrix_table)

    # â”€â”€ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° â”€â”€
    accuracy = (counts["TP"] + counts["TN"]) / total if total > 0 else 0
    precision = (
        counts["TP"] / (counts["TP"] + counts["FP"])
        if (counts["TP"] + counts["FP"]) > 0
        else 0
    )
    recall = (
        counts["TP"] / (counts["TP"] + counts["FN"])
        if (counts["TP"] + counts["FN"]) > 0
        else 0
    )
    f1 = (
        2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    )

    metrics_table = Table(
        title="ğŸ“Š ì„±ëŠ¥ ì§€í‘œ",
        show_header=True,
        header_style="bold cyan",
    )
    metrics_table.add_column("ì§€í‘œ", style="bold", width=15)
    metrics_table.add_column("ê°’", justify="center", width=15)
    metrics_table.add_row("ì´ í…ŒìŠ¤íŠ¸ ìˆ˜", str(total))
    metrics_table.add_row("Accuracy", f"{accuracy:.2%}")
    metrics_table.add_row("Precision", f"{precision:.2%}")
    metrics_table.add_row("Recall", f"{recall:.2%}")
    metrics_table.add_row("F1 Score", f"{f1:.2%}")

    rprint()
    rprint(metrics_table)

    # â”€â”€ ìš”ì•½ ë¡œê·¸ (í•œ ì¤„ ìš”ì•½) â”€â”€
    yaml_count = stats.total_yaml_files if stats else "?"
    rprint(
        f"\n[bold]ğŸ“‹ ì´ ì¤‘ Precision {precision:.2%} / "
        f"Recall {recall:.2%} / F1 Score {f1:.2%} ì…ë‹ˆë‹¤.[/bold]"
    )

    # â”€â”€ FP ìœ„í—˜ ì¼€ì´ìŠ¤ ìƒì„¸ ì¶œë ¥ â”€â”€
    fp_records = [r for r in records if r.label == "FP"]
    if fp_records:
        rprint()
        rprint(
            f"[bold red]âš ï¸  FP(ìœ„í—˜ ì¼€ì´ìŠ¤) {len(fp_records)}ê±´ ìƒì„¸ "
            f"â€” ë³´ì¥ ì•ˆ ë˜ëŠ”ë° ë³´ì¥ëœë‹¤ê³  íŒë‹¨í•œ ê±´[/bold red]"
        )
        fp_table = Table(
            title="âš ï¸ FP (False Positive) ìƒì„¸",
            show_header=True,
            header_style="bold red",
        )
        fp_table.add_column("íŒŒì¼ëª…", width=12)
        fp_table.add_column("í’ˆì¢…", width=12)
        fp_table.add_column("ì§ˆë³‘ëª…", width=20)
        fp_table.add_column("Judge ì´ìœ ", width=40)
        fp_table.add_column("Evaluator ì´ìœ ", width=40)
        for r in fp_records:
            fp_table.add_row(
                r.test_case.file_name,
                r.test_case.breed,
                r.test_case.disease_name,
                r.judge_prediction.reason[:80],
                r.evaluator_ground_truth.reason[:80],
            )
        rprint(fp_table)

    return counts


def _record_to_row(record: EvaluationRecord) -> dict[str, str | int]:
    """ë‹¨ì¼ EvaluationRecordë¥¼ CSV í–‰ìš© dictë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    tc = record.test_case
    jp = record.judge_prediction
    eg = record.evaluator_ground_truth
    return {
        "íŒŒì¼ì´ë¦„": tc.file_name,
        "ê²¬ë¬˜ì¢…": tc.breed,
        "ë‚˜ì´": tc.age,
        "ê¸°ì €ì§ˆí™˜": tc.disease_surgery_history,
        "ì¶”ì¶œì§ˆë³‘ëª…": tc.disease_name,
        "ì•½ê´€ì›ë¬¸": tc.policy_text[:200],
        "Judgeì˜ˆì¸¡": "O" if jp.is_covered else "X",
        "Judgeì´ìœ ": jp.reason,
        "Evaluatorì •ë‹µ": "O" if eg.is_covered else "X",
        "Evaluatorì´ìœ ": eg.reason,
        "ë¼ë²¨": record.label,
    }


def get_eval_csv_path() -> Path:
    """ì´ë²ˆ ì‹¤í–‰ìš© íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ CSV ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    return RESULTS_DIR / f"eval_result_{timestamp}.csv"


def init_eval_csv(csv_path: Path) -> None:
    """CSV íŒŒì¼ì„ ìƒì„±í•˜ê³  í—¤ë” í–‰ë§Œ ì”ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹œ 1íšŒ í˜¸ì¶œ."""
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    with open(csv_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=CSV_COLUMNS)
        writer.writeheader()


def append_record_to_csv(record: EvaluationRecord, csv_path: Path) -> None:
    """í‰ê°€ 1ê±´ ì™„ë£Œ ì‹œë§ˆë‹¤ CSVì— í•œ ì¤„ì„ appendí•©ë‹ˆë‹¤. ì¤‘ê°„ ì‹¤íŒ¨ ì‹œ ì´ë¯¸ ì €ì¥ëœ ê±´ê¹Œì§€ ë³´ì¡´."""
    row = _record_to_row(record)
    with open(csv_path, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=CSV_COLUMNS)
        writer.writerow(row)


def records_to_dataframe(records: list[EvaluationRecord]) -> pd.DataFrame:
    """í‰ê°€ ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    rows = [_record_to_row(r) for r in records]
    return pd.DataFrame(rows)


def save_results_to_csv(
    records: list[EvaluationRecord],
    incremental_path: Path | None = None,
) -> Path:
    """í‰ê°€ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    incremental_pathê°€ ì œê³µë˜ë©´ ì´ë¯¸ í•œ ê±´ì”© appendëœ íŒŒì¼ì´ë¯€ë¡œ,
    ë®ì–´ì“°ì§€ ì•Šê³  ê²½ë¡œì™€ ê±´ìˆ˜ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    if incremental_path is not None and incremental_path.exists():
        rprint(
            f"\n[bold green]ğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ(ì¦ë¶„ ì €ì¥): {incremental_path}[/bold green]"
        )
        rprint(f"   ì´ {len(records)}ê±´, ì»¬ëŸ¼: {CSV_COLUMNS}")
        return incremental_path

    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    csv_path = get_eval_csv_path()
    df = records_to_dataframe(records)
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    rprint(f"\n[bold green]ğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_path}[/bold green]")
    rprint(f"   ì´ {len(records)}ê±´, ì»¬ëŸ¼: {list(df.columns)}")
    return csv_path
